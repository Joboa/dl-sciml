{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Implementation of handwritten digits using MNIST database.\n",
    "\n",
    "# Import necessary modules\n",
    "import torch\n",
    "from torchvision import datasets\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import ToTensor\n",
    "import torch.nn as nn\n",
    "\n",
    "# Data training\n",
    "\n",
    "# Data testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x2071f193d90>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Hyperparameters for training\n",
    "n_epochs = 6\n",
    "batch_size_train = 64\n",
    "batch_size_test = 1000\n",
    "learning_rate = 0.01\n",
    "momentum = 0.5\n",
    "log_interval = 100\n",
    "\n",
    "random_seed = 1234\n",
    "torch.backends.cudnn.enabled = False\n",
    "torch.manual_seed(random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load MNIST dataset\n",
    "mnist_dataset = datasets.MNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor() # normalize the pixel values to [0,1] by dividing 255\n",
    ")\n",
    "\n",
    "# Train dataset\n",
    "train_loader = DataLoader(\n",
    "    mnist_dataset,\n",
    "    batch_size=batch_size_train,\n",
    "    shuffle=True \n",
    ")\n",
    "\n",
    "# Test dataset\n",
    "test_loader = DataLoader(\n",
    "    mnist_dataset,\n",
    "    batch_size=batch_size_test,\n",
    "    shuffle=True \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1000, 1, 28, 28])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check out test data\n",
    "check_test_data = enumerate(test_loader)\n",
    "batch_idx, (t_data, t_targets) = next(check_test_data)\n",
    "t_data.shape # [batch_size, channel(gray), pixel_x, pixel_y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize data\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig = plt.figure()\n",
    "for i in range(6):\n",
    "    plt.subplot(2,3, i+1)\n",
    "    plt.imshow(t_data[i][0], cmap='gray', interpolation='none')\n",
    "    plt.title(\"Ground Truth: {}\".format(t_targets[i]))\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.tight_layout()\n",
    "    # plt.show()\n",
    "# fig\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN architecture\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1,10, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(10,20, kernel_size=5)\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(320, 50)\n",
    "        self.fc2 = nn.Linear(50, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "        x = x.view(-1, 320)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x= self.fc2(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "        # return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize network\n",
    "network = Net()\n",
    "#network.cuda() # for GPU-based training\n",
    "optimizer = optim.SGD(network.parameters(), lr=learning_rate, momentum=momentum)\n",
    "# criterion = nn.CrossEntropyLoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Traing the model\n",
    "\n",
    "import os\n",
    "\n",
    "# Directory to save models\n",
    "results_dir = '/results'\n",
    "if not os.path.exists(results_dir):\n",
    "    os.makedirs(results_dir)\n",
    "\n",
    "train_losses = []\n",
    "train_counter = []\n",
    "test_losses = []\n",
    "test_counter = [i * len(train_loader.dataset) for i in range(n_epochs + 1)]\n",
    "\n",
    "def train(epoch):\n",
    "    network.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        output = network(data)\n",
    "        # loss = criterion(output, target)\n",
    "        loss = F.nll_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % log_interval == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))\n",
    "            train_losses.append(loss.item())\n",
    "            train_counter.append(\n",
    "                (batch_idx*64) + ((epoch-1)*len(train_loader.dataset)))\n",
    "            torch.save(network.state_dict(), '/results/model.pth')\n",
    "            torch.save(optimizer.state_dict(), '/results/optimizer.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test\n",
    "def test():\n",
    "    network.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            output = network(data)\n",
    "            test_loss += F.nll_loss(output, target, reduction='sum').item()\n",
    "            pred = output.data.max(1, keepdim=True)[1]\n",
    "            correct += pred.eq(target.data.view_as(pred)).sum()\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    test_losses.append(test_loss)\n",
    "    print('\\nTest set: Avg. loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.0528, Accuracy: 59050/60000 (98%)\n",
      "\n",
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 0.257956\n",
      "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 0.275588\n",
      "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 0.263501\n",
      "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 0.192284\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.193214\n",
      "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.132646\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.116310\n",
      "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 0.291893\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.242273\n",
      "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 0.067578\n",
      "\n",
      "Test set: Avg. loss: 0.0522, Accuracy: 59053/60000 (98%)\n",
      "\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.044604\n",
      "Train Epoch: 2 [6400/60000 (11%)]\tLoss: 0.045518\n",
      "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.113207\n",
      "Train Epoch: 2 [19200/60000 (32%)]\tLoss: 0.067684\n",
      "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.136158\n",
      "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.094702\n",
      "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.193215\n",
      "Train Epoch: 2 [44800/60000 (75%)]\tLoss: 0.200012\n",
      "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.131233\n",
      "Train Epoch: 2 [57600/60000 (96%)]\tLoss: 0.191386\n",
      "\n",
      "Test set: Avg. loss: 0.0514, Accuracy: 59068/60000 (98%)\n",
      "\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.214580\n",
      "Train Epoch: 3 [6400/60000 (11%)]\tLoss: 0.298932\n",
      "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.193507\n",
      "Train Epoch: 3 [19200/60000 (32%)]\tLoss: 0.163681\n",
      "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.100688\n",
      "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.354866\n",
      "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.190139\n",
      "Train Epoch: 3 [44800/60000 (75%)]\tLoss: 0.095869\n",
      "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.094818\n",
      "Train Epoch: 3 [57600/60000 (96%)]\tLoss: 0.142221\n",
      "\n",
      "Test set: Avg. loss: 0.0508, Accuracy: 59054/60000 (98%)\n",
      "\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.084318\n",
      "Train Epoch: 4 [6400/60000 (11%)]\tLoss: 0.095263\n",
      "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 0.189128\n",
      "Train Epoch: 4 [19200/60000 (32%)]\tLoss: 0.244127\n",
      "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 0.103288\n",
      "Train Epoch: 4 [32000/60000 (53%)]\tLoss: 0.189274\n",
      "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 0.119801\n",
      "Train Epoch: 4 [44800/60000 (75%)]\tLoss: 0.294266\n",
      "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 0.145293\n",
      "Train Epoch: 4 [57600/60000 (96%)]\tLoss: 0.101524\n",
      "\n",
      "Test set: Avg. loss: 0.0503, Accuracy: 59077/60000 (98%)\n",
      "\n",
      "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.112354\n",
      "Train Epoch: 5 [6400/60000 (11%)]\tLoss: 0.087644\n",
      "Train Epoch: 5 [12800/60000 (21%)]\tLoss: 0.060871\n",
      "Train Epoch: 5 [19200/60000 (32%)]\tLoss: 0.165990\n",
      "Train Epoch: 5 [25600/60000 (43%)]\tLoss: 0.054519\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[77], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m test()\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, n_epochs \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m----> 4\u001b[0m   \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m   test()\n",
      "Cell \u001b[1;32mIn[72], line 19\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(epoch)\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch_idx, (data, target) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(train_loader):\n\u001b[0;32m     18\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m---> 19\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mnetwork\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     20\u001b[0m     \u001b[38;5;66;03m# loss = criterion(output, target)\u001b[39;00m\n\u001b[0;32m     21\u001b[0m     loss \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mnll_loss(output, target)\n",
      "File \u001b[1;32mc:\\Users\\johna\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Cell \u001b[1;32mIn[69], line 15\u001b[0m, in \u001b[0;36mNet.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m---> 15\u001b[0m     x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(\u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_pool2d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[0;32m     16\u001b[0m     x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(F\u001b[38;5;241m.\u001b[39mmax_pool2d(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv2_drop(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv2(x)), \u001b[38;5;241m2\u001b[39m))\n\u001b[0;32m     17\u001b[0m     x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m320\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\johna\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\_jit_internal.py:484\u001b[0m, in \u001b[0;36mboolean_dispatch.<locals>.fn\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    482\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m if_true(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    483\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 484\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mif_false\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\johna\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\functional.py:782\u001b[0m, in \u001b[0;36m_max_pool2d\u001b[1;34m(input, kernel_size, stride, padding, dilation, ceil_mode, return_indices)\u001b[0m\n\u001b[0;32m    780\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m stride \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    781\u001b[0m     stride \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mjit\u001b[38;5;241m.\u001b[39mannotate(List[\u001b[38;5;28mint\u001b[39m], [])\n\u001b[1;32m--> 782\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_pool2d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkernel_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mceil_mode\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Run training\n",
    "test()\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "  train(epoch)\n",
    "  test()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
