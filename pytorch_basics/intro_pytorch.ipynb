{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [[1,2], [3,4]]\n",
    "x_data = torch.tensor(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numpy np_array value: \n",
      " [[1 2]\n",
      " [3 4]] \n",
      "\n",
      "Tensor x_np value: \n",
      " tensor([[1, 2],\n",
      "        [3, 4]], dtype=torch.int32) \n",
      "\n",
      "Numpy np_array after * 2 operation: \n",
      " [[2 4]\n",
      " [6 8]] \n",
      "\n",
      "Tensor x_np value after modifying numpy array: \n",
      " tensor([[2, 4],\n",
      "        [6, 8]], dtype=torch.int32) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# From numpy array\n",
    "np_array = np.array(data)\n",
    "x_np = torch.from_numpy(np_array)\n",
    "\n",
    "print(f\"Numpy np_array value: \\n {np_array} \\n\")\n",
    "print(f\"Tensor x_np value: \\n {x_np} \\n\")\n",
    "\n",
    "np.multiply(np_array, 2, out=np_array)\n",
    "print(f\"Numpy np_array after * 2 operation: \\n {np_array} \\n\")\n",
    "print(f\"Tensor x_np value after modifying numpy array: \\n {x_np} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ones Tensor: \n",
      " tensor([[1, 1],\n",
      "        [1, 1]]) \n",
      "\n",
      "Random Tensor: \n",
      " tensor([[0.9566, 0.8728],\n",
      "        [0.9157, 0.2495]]) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# From another tensor\n",
    "x_ones = torch.ones_like(x_data) # retains the properties of x_data\n",
    "print(f\"Ones Tensor: \\n {x_ones} \\n\")\n",
    "\n",
    "x_rand = torch.rand_like(x_data, dtype=torch.float)\n",
    "print(f\"Random Tensor: \\n {x_rand} \\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Tensor: \n",
      " tensor([[0.2286, 0.3099, 0.8449],\n",
      "        [0.5508, 0.9943, 0.6485]]) \n",
      "\n",
      "Ones Tensor: \n",
      " tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]]) \n",
      "\n",
      "Zeros Tensor: \n",
      " tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "# Random or constant values\n",
    "shape = (2,3)\n",
    "rand_tensor = torch.rand(shape)\n",
    "ones_tensor = torch.ones(shape)\n",
    "zeros_tensor = torch.zeros(shape)\n",
    "\n",
    "print(f\"Random Tensor: \\n {rand_tensor} \\n\")\n",
    "print(f\"Ones Tensor: \\n {ones_tensor} \\n\")\n",
    "print(f\"Zeros Tensor: \\n {zeros_tensor}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of tensor: torch.Size([3, 4])\n",
      "Datatype of tensor: torch.float32\n",
      "Device tensor is stored on: cpu\n"
     ]
    }
   ],
   "source": [
    "# Tensor attributes\n",
    "tensor = torch.rand(3,4)\n",
    "\n",
    "print(f\"Shape of tensor: {tensor.shape}\")\n",
    "print(f\"Datatype of tensor: {tensor.dtype}\")\n",
    "print(f\"Device tensor is stored on: {tensor.device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Operations on tensors\n",
    "# To GPU\n",
    "if  torch.cuda.is_available():\n",
    "    tensor = tensor.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First row:  tensor([1., 1., 1., 1.])\n",
      "First column:  tensor([1., 1., 1., 1.])\n",
      "Last column: tensor([1., 1., 1., 1.])\n",
      "tensor([[1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "# Standard numpy-like indexing and slicing\n",
    "tensor = torch.ones(4,4)\n",
    "print('First row: ',tensor[0])\n",
    "print('First column: ', tensor[:, 0])\n",
    "print('Last column:', tensor[..., -1])\n",
    "tensor[:,1] = 0\n",
    "print(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.]])\n",
      "tensor([[1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "# Joining tensors\n",
    "t1 = torch.cat([tensor, tensor, tensor], dim=1)\n",
    "print(t1)\n",
    "\n",
    "t2 = torch.cat([tensor, tensor, tensor], dim=0)\n",
    "print(t2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y1:  tensor([[3., 3., 3., 3.],\n",
      "        [3., 3., 3., 3.],\n",
      "        [3., 3., 3., 3.],\n",
      "        [3., 3., 3., 3.]])\n",
      "y2:  tensor([[3., 3., 3., 3.],\n",
      "        [3., 3., 3., 3.],\n",
      "        [3., 3., 3., 3.],\n",
      "        [3., 3., 3., 3.]])\n",
      "y3:  tensor([[3., 3., 3., 3.],\n",
      "        [3., 3., 3., 3.],\n",
      "        [3., 3., 3., 3.],\n",
      "        [3., 3., 3., 3.]])\n",
      "z1:  tensor([[1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.]])\n",
      "z2:  tensor([[1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.]])\n",
      "z3:  tensor([[1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "# Arithmetic operations\n",
    "\n",
    "# Matrix multiplication\n",
    "y1 = tensor @ tensor.T\n",
    "print(\"y1: \", y1)\n",
    "y2 = tensor.matmul(tensor.T)\n",
    "print(\"y2: \", y2)\n",
    "\n",
    "y3 = torch.rand_like(tensor)\n",
    "torch.matmul(tensor, tensor.T, out=y3)\n",
    "print(\"y3: \", y3)\n",
    "\n",
    "# Element-wise product\n",
    "z1 = tensor * tensor\n",
    "print(\"z1: \", z1)\n",
    "z2 = tensor.mul(tensor)\n",
    "print(\"z2: \", z2)\n",
    "\n",
    "z3 = torch.rand_like(tensor)\n",
    "torch.mul(tensor, tensor, out=z3)\n",
    "print(\"z3: \", z3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(12.) <class 'torch.Tensor'>\n",
      "12.0 <class 'float'>\n"
     ]
    }
   ],
   "source": [
    "# Single-elements tensors\n",
    "agg = tensor.sum()\n",
    "print(agg, type(agg))\n",
    "agg_item = agg.item()\n",
    "print(agg_item, type(agg_item))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.]]) \n",
      "\n",
      "tensor([[6., 5., 6., 6.],\n",
      "        [6., 5., 6., 6.],\n",
      "        [6., 5., 6., 6.],\n",
      "        [6., 5., 6., 6.]])\n"
     ]
    }
   ],
   "source": [
    "# In-place operations\n",
    "\"\"\"\n",
    "Operations that store the result into the operand are \n",
    "called in-place. They're denoted by a _ suffix. \n",
    "For example: x.copy_(y), x.t_(), will change x.\n",
    "\"\"\"\n",
    "print(tensor, \"\\n\")\n",
    "tensor.add_(5)\n",
    "print(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t: tensor([1., 1., 1., 1., 1.])\n",
      "n: [1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "# Bridge with numpy\n",
    "\n",
    "# 1. Tensor to Numpy array\n",
    "t = torch.ones(5)\n",
    "print(f\"t: {t}\")\n",
    "n = t.numpy()\n",
    "print(f\"n: {n}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t: tensor([2., 2., 2., 2., 2.])\n",
      "n: [2. 2. 2. 2. 2.]\n"
     ]
    }
   ],
   "source": [
    "t.add_(1)\n",
    "print(f\"t: {t}\")\n",
    "print(f\"n: {n}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numpy array to tensor\n",
    "n = np.ones(5)\n",
    "t = torch.from_numpy(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t: tensor([2., 2., 2., 2., 2.], dtype=torch.float64)\n",
      "n: [2. 2. 2. 2. 2.]\n"
     ]
    }
   ],
   "source": [
    "np.add(n, 1, out=n)\n",
    "print(f\"t: {t}\")\n",
    "print(f\"n: {n}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\johna\\miniconda3\\envs\\env\\Lib\\site-packages\\onnxruntime\\capi\\onnxruntime_validation.py:26: UserWarning: Unsupported Windows version (11). ONNX Runtime supports Windows 10 and above, only.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Datasets and Dataloaders\n",
    "\"\"\"\n",
    "Dataset stores the samples and their corresponding labels, \n",
    "and DataLoader wraps an iterable around the Dataset to \n",
    "enable easy access to the samples\n",
    "\"\"\"\n",
    "# Loading a dataset \n",
    "\n",
    "%matplotlib inline\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor, Lambda\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "training_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")\n",
    "\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x800 with 9 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Iterating and visualizing the Dataset\n",
    "\n",
    "labels_map = {\n",
    "    0: \"T-Shirt\",\n",
    "    1: \"Trouser\",\n",
    "    2: \"Pullover\",\n",
    "    3: \"Dress\",\n",
    "    4: \"Coat\",\n",
    "    5: \"Sandal\",\n",
    "    6: \"Shirt\",\n",
    "    7: \"Sneaker\",\n",
    "    8: \"Bag\",\n",
    "    9: \"Ankle Boot\",\n",
    "}\n",
    "\n",
    "figure = plt.figure(figsize=(8,8))\n",
    "cols, rows = 3, 3\n",
    "for i in range(1, cols * rows + 1):\n",
    "    sample_idx = torch.randint(len(training_data), size=(1,)).item()\n",
    "    img, label = training_data[sample_idx]\n",
    "    figure.add_subplot(rows, cols, i)\n",
    "    plt.title(labels_map[label])\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow(img.squeeze(), cmap=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing data for training with DataLoaders\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_dataloader = DataLoader(training_data, batch_size=64, shuffle=True)\n",
    "test_dataloader = DataLoader(test_data, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature batch shape: torch.Size([64, 1, 28, 28])\n",
      "Labels batch shape: torch.Size([64])\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaEAAAGdCAYAAAC7EMwUAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAcG0lEQVR4nO3df2yV5f3/8dcB2iM/To+Q2nNOR6mNwbgIIREZSFTQaD82GRNxCWq2lH+MTiAj1ZgxslBdQo2JxD+YLjML0ygbyYZoIlPrsIWFsSDiQOZY1bKWwVljxXNKS08tXN8/iOfrkR/2ujmn7572+UiuhHOf68199erVvnqfH9cJOeecAAAwMM56AACAsYsQAgCYIYQAAGYIIQCAGUIIAGCGEAIAmCGEAABmCCEAgJkJ1gP4prNnz+r48eOKRCIKhULWwwEAeHLOqaenR5WVlRo37tLXOiMuhI4fP66qqirrYQAALlNnZ6emT59+yT4j7uG4SCRiPQQAQB4M5fd5wULoueeeU01Nja644grNnTtXu3fvHlIdD8EBwOgwlN/nBQmhrVu3as2aNVq3bp0OHDigW265RXV1dero6CjE6QAARSpUiF2058+frxtuuEHPP/989th3v/tdLV26VE1NTZesTafTikaj+R4SAGCYpVIplZWVXbJP3q+EBgYGtH//ftXW1uYcr62t1Z49e87rn8lklE6ncxoAYGzIewh99tlnOnPmjGKxWM7xWCymZDJ5Xv+mpiZFo9Fs45VxADB2FOyFCd98Qso5d8EnqdauXatUKpVtnZ2dhRoSAGCEyfv7hMrLyzV+/Pjzrnq6urrOuzqSpHA4rHA4nO9hAACKQN6vhEpLSzV37lw1NzfnHG9ubtbChQvzfToAQBEryI4JDQ0N+vGPf6wbb7xRN910k37zm9+oo6NDDz/8cCFOBwAoUgUJoeXLl6u7u1tPPvmkTpw4oVmzZmnHjh2qrq4uxOkAAEWqIO8Tuhy8TwgARgeT9wkBADBUhBAAwAwhBAAwQwgBAMwQQgAAM4QQAMAMIQQAMEMIAQDMEEIAADOEEADADCEEADBDCAEAzBBCAAAzhBAAwAwhBAAwQwgBAMwQQgAAM4QQAMAMIQQAMEMIAQDMEEIAADOEEADADCEEADBDCAEAzBBCAAAzhBAAwAwhBAAwQwgBAMwQQgAAM4QQAMAMIQQAMEMIAQDMEEIAADOEEADADCEEADBDCAEAzBBCAAAzhBAAwAwhBAAwQwgBAMwQQgAAM4QQAMAMIQQAMEMIAQDMEEIAADOEEADADCEEADBDCAEAzBBCAAAzhBAAwAwhBAAwQwgBAMwQQgAAM4QQAMAMIQQAMJP3EGpsbFQoFMpp8Xg836cBAIwCEwrxn15//fV65513srfHjx9fiNMAAIpcQUJowoQJXP0AAL5VQZ4TamtrU2VlpWpqanTffffp008/vWjfTCajdDqd0wAAY0PeQ2j+/Pl66aWX9NZbb+mFF15QMpnUwoUL1d3dfcH+TU1Nikaj2VZVVZXvIQEARqiQc84V8gS9vb265ppr9Pjjj6uhoeG8+zOZjDKZTPZ2Op0miABgFEilUiorK7tkn4I8J/R1kydP1uzZs9XW1nbB+8PhsMLhcKGHAQAYgQr+PqFMJqOPPvpIiUSi0KcCABSZvIfQY489ptbWVrW3t+vvf/+7fvjDHyqdTqu+vj7fpwIAFLm8Pxx37Ngx3X///frss8901VVXacGCBdq7d6+qq6vzfSoAQJEr+AsTfKXTaUWjUethAAAu01BemMDecQAAM4QQAMAMIQQAMEMIAQDMEEIAADOEEADADCEEADBDCAEAzBBCAAAzhBAAwAwhBAAwQwgBAMwQQgAAM4QQAMAMIQQAMEMIAQDMEEIAADOEEADADCEEADBDCAEAzBBCAAAzhBAAwAwhBAAwQwgBAMwQQgAAM4QQAMDMBOsBYGwZN87/756zZ88WYCTF57XXXvOumTx5cqBz3XHHHYHqRpsg6zWIsbzGuRICAJghhAAAZgghAIAZQggAYIYQAgCYIYQAAGYIIQCAGUIIAGCGEAIAmCGEAABmCCEAgBlCCABghg1MMaxG40aNFRUV3jV/+ctfvGtOnTrlXVNSUuJdI0kHDx70rlmwYIF3TV9fn3dNEEE3Ig1SNzg4GOhcvtavXx+obvv27d41//jHPwKdayi4EgIAmCGEAABmCCEAgBlCCABghhACAJghhAAAZgghAIAZQggAYIYQAgCYIYQAAGYIIQCAGUIIAGAm5Jxz1oP4unQ6rWg0aj0MYMiC/Ah98skn3jWZTMa75vTp0941klRZWeld09vb611zzz33eNd8+OGH3jUj3b333utd88c//jHQuYJsnnvHHXcEOlcqlVJZWdkl+3AlBAAwQwgBAMx4h9CuXbu0ZMkSVVZWKhQKnffZFM45NTY2qrKyUhMnTtTixYt1+PDhfI0XADCKeIdQb2+v5syZo02bNl3w/qefflobN27Upk2btG/fPsXjcd15553q6em57MECAEYX709WraurU11d3QXvc87p2Wef1bp167Rs2TJJ0osvvqhYLKYtW7booYceurzRAgBGlbw+J9Te3q5kMqna2trssXA4rEWLFmnPnj0XrMlkMkqn0zkNADA25DWEksmkJCkWi+Ucj8Vi2fu+qampSdFoNNuqqqryOSQAwAhWkFfHhUKhnNvOufOOfWXt2rVKpVLZ1tnZWYghAQBGIO/nhC4lHo9LOndFlEgksse7urrOuzr6SjgcVjgczucwAABFIq9XQjU1NYrH42pubs4eGxgYUGtrqxYuXJjPUwEARgHvK6FTp07p448/zt5ub2/XBx98oGnTpmnGjBlas2aNNmzYoJkzZ2rmzJnasGGDJk2apAceeCCvAwcAFD/vEHrvvfd02223ZW83NDRIkurr6/W73/1Ojz/+uE6fPq1HHnlEJ0+e1Pz58/X2228rEonkb9QAgFGBDUwxKi1atChQ3dcfSh6q9957z7tm/Pjx3jVTp071rhkcHPSuCVoX5Od2ypQp3jX//ve/vWv27dvnXSMp0B/Pt99+u3dNf3+/d01paal3jSS9//773jVBNliV2MAUADDCEUIAADOEEADADCEEADBDCAEAzBBCAAAzhBAAwAwhBAAwQwgBAMwQQgAAM4QQAMAMIQQAMEMIAQDMjJpdtMeN88/Ti33keCHOFUSQb02Qr+nLL7/0rhlOW7Zs8a75v//7v0DnSiaT3jVBdkAOMudf/7TioZoxY4Z3jSQdO3bMu6anp8e75vTp0941FRUV3jXl5eXeNVKw3cSPHj3qXTOcny599dVXe9cE3bGbXbQBACMaIQQAMEMIAQDMEEIAADOEEADADCEEADBDCAEAzBBCAAAzhBAAwAwhBAAwQwgBAMwQQgAAMxOsB5AvZ8+eHbZznTlzZtjONZLNnTvXu+bPf/6zd006nfauOXTokHeNJF155ZXeNdOnT/euef/9971rPvzwQ++aWCzmXSNJkydP9q4JMg9BNiM9deqUd01XV5d3jSRNmOD/KzLI3AXZKDXI5q+SVFJS4l1z/fXXe/U/c+aM/vWvfw2pL1dCAAAzhBAAwAwhBAAwQwgBAMwQQgAAM4QQAMAMIQQAMEMIAQDMEEIAADOEEADADCEEADBDCAEAzIyaDUyDmDhxYqC6SCTiXVNZWeldU1VV5V3jnPOuueOOO7xrJOmnP/2pd81QNzX8umPHjnnXBNl4UpIOHjzoXfPJJ59411x33XXeNbNmzfKuSSaT3jWSVFpa6l3T3d3tXRNks88gP3+TJk3yrpGCfW9TqZR3TW9vr3dNkE1PJWn27NneNT/60Y+8+vf39+uJJ54YUl+uhAAAZgghAIAZQggAYIYQAgCYIYQAAGYIIQCAGUIIAGCGEAIAmCGEAABmCCEAgBlCCABghhACAJgZsRuY/uAHP1BJScmQ+z/55JPe54jFYt41UrCNT4PU9PT0eNek02nvmqNHj3rXSNK2bdu8axKJhHfNFVdc4V1z5MgR7xpJKi8v966JRqPeNVdeeaV3zX//+1/vmnA47F0TVEVFhXfNlClTvGvOnj3rXdPX1+ddIwXb+DRIzdSpU71rMpmMd40kdXR0eNf4bjQ7btzQr2+4EgIAmCGEAABmvENo165dWrJkiSorKxUKhbR9+/ac+1esWKFQKJTTFixYkK/xAgBGEe8Q6u3t1Zw5c7Rp06aL9rnrrrt04sSJbNuxY8dlDRIAMDp5vzChrq5OdXV1l+wTDocVj8cDDwoAMDYU5DmhlpYWVVRU6Nprr9WDDz6orq6ui/bNZDJKp9M5DQAwNuQ9hOrq6vTKK69o586deuaZZ7Rv3z7dfvvtF305YVNTk6LRaLZVVVXle0gAgBEq7+8TWr58efbfs2bN0o033qjq6mq98cYbWrZs2Xn9165dq4aGhuztdDpNEAHAGFHwN6smEglVV1erra3tgveHw+FhfUMdAGDkKPj7hLq7u9XZ2RnonfIAgNHN+0ro1KlT+vjjj7O329vb9cEHH2jatGmaNm2aGhsbde+99yqRSOjo0aP6+c9/rvLyct1zzz15HTgAoPh5h9B7772n2267LXv7q+dz6uvr9fzzz+vQoUN66aWX9MUXXyiRSOi2227T1q1bFYlE8jdqAMCoEHLOOetBfF06nVY0GtU777zjtWne9OnTvc/1xRdfeNdI5x5i9DUwMOBd8+WXX3rXBHnYM+gSCPKHRZBNF0tLS71rgmwYK0mnT5/2rvn888+9ayZM8H86Nsh8B92kN8h6HRwc9K45deqUd00oFBqWGkkaP368d02QDVaDzF2Q3w+SVFZW5l3z8ssve/Xv7+/XL3/5S6VSqW89H3vHAQDMEEIAADOEEADADCEEADBDCAEAzBBCAAAzhBAAwAwhBAAwQwgBAMwQQgAAM4QQAMAMIQQAMEMIAQDMFPyTVYPq6OjQpEmThtw/yC7a48YFy+Ag5wqyi2+Q3XiD7Dgd9JNtg3xNXV1dgc7lK+gOw1OnTvWuKS8vD3QuX/39/d41x44dC3SuIPMXdOdyX0F2fQ+6U3yQ3xFBvk9BftaD7EAuBZuL1tZWr/4+u4JzJQQAMEMIAQDMEEIAADOEEADADCEEADBDCAEAzBBCAAAzhBAAwAwhBAAwQwgBAMwQQgAAM4QQAMDMiN3A9KGHHvLaILOtrc37HEE3nsxkMoHqfAXdhNNXX19foLogG5gO12afQb+mnp4e75og36cgNWfOnBmWmqB6e3u9a4Js3BnE+PHjA9UFWUdB5mHy5MneNVOmTPGukaRYLOZdE41Gvfr7rG+uhAAAZgghAIAZQggAYIYQAgCYIYQAAGYIIQCAGUIIAGCGEAIAmCGEAABmCCEAgBlCCABghhACAJgZsRuY+m7wWF1d7X2O+vp67xrp3OaqvmbPnu1dE2SDwsHBwWGpkYJt1Hjy5EnvmiCbcPb393vXSJJzzrtmYGDAu2bcOP+//yZM8P9xLS0t9a4JWldSUuJdE2QegtQE+b4GPdeVV17pXRPkZz3IupOCfW/nzZvn1b+/v1/bt28fUl+uhAAAZgghAIAZQggAYIYQAgCYIYQAAGYIIQCAGUIIAGCGEAIAmCGEAABmCCEAgBlCCABghhACAJgJuaA7+xVIOp1WNBqVJIVCoSHXjbAvIy+uu+4675oZM2Z411x99dXeNVKwTWPLy8u9a4Js7jh16lTvGknKZDLeNdOmTfOuCbKJ5HBuTjtcP09B5tt3c2Mp2OavktTX1+dd097e7l3z+eefe9e0tbV510jS7t27vWv+97//BTpXKpVSWVnZJftwJQQAMEMIAQDMeIVQU1OT5s2bp0gkooqKCi1dulRHjhzJ6eOcU2NjoyorKzVx4kQtXrxYhw8fzuugAQCjg1cItba2auXKldq7d6+am5s1ODio2tranA83e/rpp7Vx40Zt2rRJ+/btUzwe15133qmenp68Dx4AUNy8nq178803c25v3rxZFRUV2r9/v2699VY55/Tss89q3bp1WrZsmSTpxRdfVCwW05YtWwJ9IikAYPS6rOeEUqmUpP//6qD29nYlk0nV1tZm+4TDYS1atEh79uy54P+RyWSUTqdzGgBgbAgcQs45NTQ06Oabb9asWbMkSclkUpIUi8Vy+sZisex939TU1KRoNJptVVVVQYcEACgygUNo1apVOnjwoH7/+9+fd98339/jnLvoe37Wrl2rVCqVbZ2dnUGHBAAoMoHewbV69Wq9/vrr2rVrl6ZPn549Ho/HJZ27IkokEtnjXV1d510dfSUcDiscDgcZBgCgyHldCTnntGrVKm3btk07d+5UTU1Nzv01NTWKx+Nqbm7OHhsYGFBra6sWLlyYnxEDAEYNryuhlStXasuWLXrttdcUiUSyz/NEo1FNnDhRoVBIa9as0YYNGzRz5kzNnDlTGzZs0KRJk/TAAw8U5AsAABQvrxB6/vnnJUmLFy/OOb5582atWLFCkvT444/r9OnTeuSRR3Ty5EnNnz9fb7/9tiKRSF4GDAAYPUb0BqYAgOLFBqYAgBGNEAIAmCGEAABmCCEAgBlCCABghhACAJghhAAAZgghAIAZQggAYIYQAgCYIYQAAGYIIQCAGUIIAGCGEAIAmCGEAABmCCEAgBlCCABghhACAJghhAAAZgghAIAZQggAYIYQAgCYIYQAAGYIIQCAGUIIAGCGEAIAmCGEAABmCCEAgBlCCABghhACAJghhAAAZgghAIAZQggAYIYQAgCYIYQAAGYIIQCAGUIIAGCGEAIAmCGEAABmCCEAgBlCCABghhACAJghhAAAZgghAIAZQggAYIYQAgCYIYQAAGYIIQCAGUIIAGCGEAIAmCGEAABmCCEAgBlCCABghhACAJghhAAAZrxCqKmpSfPmzVMkElFFRYWWLl2qI0eO5PRZsWKFQqFQTluwYEFeBw0AGB28Qqi1tVUrV67U3r171dzcrMHBQdXW1qq3tzen31133aUTJ05k244dO/I6aADA6DDBp/Obb76Zc3vz5s2qqKjQ/v37deutt2aPh8NhxePx/IwQADBqXdZzQqlUSpI0bdq0nOMtLS2qqKjQtddeqwcffFBdXV0X/T8ymYzS6XROAwCMDSHnnAtS6JzT3XffrZMnT2r37t3Z41u3btWUKVNUXV2t9vZ2/eIXv9Dg4KD279+vcDh83v/T2NioJ554IvhXAAAYkVKplMrKyi7dyQX0yCOPuOrqatfZ2XnJfsePH3clJSXuT3/60wXv7+/vd6lUKts6OzudJBqNRqMVeUulUt+aJV7PCX1l9erVev3117Vr1y5Nnz79kn0TiYSqq6vV1tZ2wfvD4fAFr5AAAKOfVwg557R69Wq9+uqramlpUU1NzbfWdHd3q7OzU4lEIvAgAQCjk9cLE1auXKmXX35ZW7ZsUSQSUTKZVDKZ1OnTpyVJp06d0mOPPaa//e1vOnr0qFpaWrRkyRKVl5frnnvuKcgXAAAoYj7PA+kij/tt3rzZOedcX1+fq62tdVdddZUrKSlxM2bMcPX19a6jo2PI50ilUuaPY9JoNBrt8ttQnhMK/Oq4Qkmn04pGo9bDAABcpqG8Oo694wAAZgghAIAZQggAYIYQAgCYIYQAAGYIIQCAGUIIAGCGEAIAmCGEAABmCCEAgBlCCABghhACAJghhAAAZgghAIAZQggAYIYQAgCYIYQAAGYIIQCAGUIIAGCGEAIAmCGEAABmCCEAgBlCCABghhACAJghhAAAZkZcCDnnrIcAAMiDofw+H3Eh1NPTYz0EAEAeDOX3eciNsEuPs2fP6vjx44pEIgqFQjn3pdNpVVVVqbOzU2VlZUYjtMc8nMM8nMM8nMM8nDMS5sE5p56eHlVWVmrcuEtf60wYpjEN2bhx4zR9+vRL9ikrKxvTi+wrzMM5zMM5zMM5zMM51vMQjUaH1G/EPRwHABg7CCEAgJmiCqFwOKz169crHA5bD8UU83AO83AO83AO83BOsc3DiHthAgBg7CiqKyEAwOhCCAEAzBBCAAAzhBAAwExRhdBzzz2nmpoaXXHFFZo7d652795tPaRh1djYqFAolNPi8bj1sApu165dWrJkiSorKxUKhbR9+/ac+51zamxsVGVlpSZOnKjFixfr8OHDNoMtoG+bhxUrVpy3PhYsWGAz2AJpamrSvHnzFIlEVFFRoaVLl+rIkSM5fcbCehjKPBTLeiiaENq6davWrFmjdevW6cCBA7rllltUV1enjo4O66ENq+uvv14nTpzItkOHDlkPqeB6e3s1Z84cbdq06YL3P/3009q4caM2bdqkffv2KR6P68477xx1+xB+2zxI0l133ZWzPnbs2DGMIyy81tZWrVy5Unv37lVzc7MGBwdVW1ur3t7ebJ+xsB6GMg9SkawHVyS+973vuYcffjjn2HXXXed+9rOfGY1o+K1fv97NmTPHehimJLlXX301e/vs2bMuHo+7p556Knusv7/fRaNR9+tf/9pghMPjm/PgnHP19fXu7rvvNhmPla6uLifJtba2OufG7nr45jw4VzzroSiuhAYGBrR//37V1tbmHK+trdWePXuMRmWjra1NlZWVqqmp0X333adPP/3Uekim2tvblUwmc9ZGOBzWokWLxtzakKSWlhZVVFTo2muv1YMPPqiuri7rIRVUKpWSJE2bNk3S2F0P35yHrxTDeiiKEPrss8905swZxWKxnOOxWEzJZNJoVMNv/vz5eumll/TWW2/phRdeUDKZ1MKFC9Xd3W09NDNfff/H+tqQpLq6Or3yyivauXOnnnnmGe3bt0+33367MpmM9dAKwjmnhoYG3XzzzZo1a5aksbkeLjQPUvGshxG3i/alfPOjHZxz5x0bzerq6rL/nj17tm666SZdc801evHFF9XQ0GA4MntjfW1I0vLly7P/njVrlm688UZVV1frjTfe0LJlywxHVhirVq3SwYMH9de//vW8+8bSerjYPBTLeiiKK6Hy8nKNHz/+vL9kurq6zvuLZyyZPHmyZs+erba2NuuhmPnq1YGsjfMlEglVV1ePyvWxevVqvf7663r33XdzPvplrK2Hi83DhYzU9VAUIVRaWqq5c+equbk553hzc7MWLlxoNCp7mUxGH330kRKJhPVQzNTU1Cgej+esjYGBAbW2to7ptSFJ3d3d6uzsHFXrwzmnVatWadu2bdq5c6dqampy7h8r6+Hb5uFCRux6MHxRhJc//OEPrqSkxP32t791//znP92aNWvc5MmT3dGjR62HNmweffRR19LS4j799FO3d+9e9/3vf99FIpFRPwc9PT3uwIED7sCBA06S27hxoztw4ID7z3/+45xz7qmnnnLRaNRt27bNHTp0yN1///0ukUi4dDptPPL8utQ89PT0uEcffdTt2bPHtbe3u3fffdfddNNN7jvf+c6omoef/OQnLhqNupaWFnfixIls6+vry/YZC+vh2+ahmNZD0YSQc8796le/ctXV1a60tNTdcMMNOS9HHAuWL1/uEomEKykpcZWVlW7ZsmXu8OHD1sMquHfffddJOq/V19c75869LHf9+vUuHo+7cDjsbr31Vnfo0CHbQRfApeahr6/P1dbWuquuusqVlJS4GTNmuPr6etfR0WE97Ly60NcvyW3evDnbZyysh2+bh2JaD3yUAwDATFE8JwQAGJ0IIQCAGUIIAGCGEAIAmCGEAABmCCEAgBlCCABghhACAJghhAAAZgghAIAZQggAYIYQAgCY+X99Y9nQebBbvAAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: Sneaker\n"
     ]
    }
   ],
   "source": [
    "# Display image and label\n",
    "train_features, train_labels = next(iter(train_dataloader))\n",
    "print(f\"Feature batch shape: {train_features.size()}\")\n",
    "print(f\"Labels batch shape: {train_labels.size()}\")\n",
    "img = train_features[0].squeeze()\n",
    "label = train_labels[0]\n",
    "plt.imshow(img, cmap=\"gray\")\n",
    "plt.show()\n",
    "label_name = list(labels_map.values())[label]\n",
    "print(f\"Label: {label_name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalization\n",
    "\"\"\"data preprocessing technique that's applied to scale or \n",
    "transform the data to make sure there's an equal learning \n",
    "contribution from each feature (Microsoft)\n",
    "\"\"\"\n",
    "\n",
    "# Transforms\n",
    "\"\"\"Manipulate the data to make it suitable for training\"\"\"\n",
    "\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor, Lambda\n",
    "\n",
    "ds = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor(), # converts to tensor and scale in range [0,1]\n",
    "    target_transform=Lambda(lambda y: torch.zeros(10, dtype=torch.float)\n",
    "                            .scatter_(0, torch.tensor(y), value=1))\n",
    "                            # torch.nn.functional.one_hot\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "# Building a neural network\n",
    "import torch.nn as nn\n",
    "\n",
    "# Get hardware for training\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print('Using {} device'.format(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the network class\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28*28, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512,512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
      "    (5): ReLU()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Instance of the NeuralNEtwork\n",
    "model = NeuralNetwork().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizing the model parameters\n",
    "# seting hyperparameters\n",
    "learning_rate = 1e-3\n",
    "batch_size = 64\n",
    "epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and test\n",
    "def train_loop(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    for batch, (X,y) in enumerate(dataloader):\n",
    "        # computer prediction and loss\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss , current = loss.item(), batch * len(X)\n",
    "            print(f\"loss: {loss:>7f} [{current:>5d}/{size:>5d}]\")\n",
    "\n",
    "def test_loop(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    test_loss, correct = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "\n",
    "    test_loss /=size\n",
    "    correct /=size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 2.301643 [    0/60000]\n",
      "loss: 2.293468 [ 6400/60000]\n",
      "loss: 2.287719 [12800/60000]\n",
      "loss: 2.279521 [19200/60000]\n",
      "loss: 2.264322 [25600/60000]\n",
      "loss: 2.264799 [32000/60000]\n",
      "loss: 2.235586 [38400/60000]\n",
      "loss: 2.256524 [44800/60000]\n",
      "loss: 2.223070 [51200/60000]\n",
      "loss: 2.206876 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 40.5%, Avg loss: 0.034841 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 2.224434 [    0/60000]\n",
      "loss: 2.206681 [ 6400/60000]\n",
      "loss: 2.234478 [12800/60000]\n",
      "loss: 2.172060 [19200/60000]\n",
      "loss: 2.155501 [25600/60000]\n",
      "loss: 2.148893 [32000/60000]\n",
      "loss: 2.127159 [38400/60000]\n",
      "loss: 2.095894 [44800/60000]\n",
      "loss: 2.057322 [51200/60000]\n",
      "loss: 2.136148 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 43.9%, Avg loss: 0.033027 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 2.134140 [    0/60000]\n",
      "loss: 2.113019 [ 6400/60000]\n",
      "loss: 2.053939 [12800/60000]\n",
      "loss: 2.021535 [19200/60000]\n",
      "loss: 1.944070 [25600/60000]\n",
      "loss: 2.033104 [32000/60000]\n",
      "loss: 1.968898 [38400/60000]\n",
      "loss: 1.871545 [44800/60000]\n",
      "loss: 1.970140 [51200/60000]\n",
      "loss: 1.899499 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 43.6%, Avg loss: 0.030118 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 1.816003 [    0/60000]\n",
      "loss: 1.989805 [ 6400/60000]\n",
      "loss: 1.886436 [12800/60000]\n",
      "loss: 1.798962 [19200/60000]\n",
      "loss: 1.807982 [25600/60000]\n",
      "loss: 1.701000 [32000/60000]\n",
      "loss: 1.773695 [38400/60000]\n",
      "loss: 1.810128 [44800/60000]\n",
      "loss: 1.731776 [51200/60000]\n",
      "loss: 1.746703 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 53.2%, Avg loss: 0.027429 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 1.721204 [    0/60000]\n",
      "loss: 1.707291 [ 6400/60000]\n",
      "loss: 1.823496 [12800/60000]\n",
      "loss: 1.734402 [19200/60000]\n",
      "loss: 1.686393 [25600/60000]\n",
      "loss: 1.709624 [32000/60000]\n",
      "loss: 1.505382 [38400/60000]\n",
      "loss: 1.730044 [44800/60000]\n",
      "loss: 1.845277 [51200/60000]\n",
      "loss: 1.755983 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 56.5%, Avg loss: 0.025416 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 1.627015 [    0/60000]\n",
      "loss: 1.540816 [ 6400/60000]\n",
      "loss: 1.639232 [12800/60000]\n",
      "loss: 1.456962 [19200/60000]\n",
      "loss: 1.714430 [25600/60000]\n",
      "loss: 1.420616 [32000/60000]\n",
      "loss: 1.416244 [38400/60000]\n",
      "loss: 1.826095 [44800/60000]\n",
      "loss: 1.395892 [51200/60000]\n",
      "loss: 1.438726 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 56.8%, Avg loss: 0.023920 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 1.473055 [    0/60000]\n",
      "loss: 1.477548 [ 6400/60000]\n",
      "loss: 1.419411 [12800/60000]\n",
      "loss: 1.432560 [19200/60000]\n",
      "loss: 1.397140 [25600/60000]\n",
      "loss: 1.348437 [32000/60000]\n",
      "loss: 1.436801 [38400/60000]\n",
      "loss: 1.435632 [44800/60000]\n",
      "loss: 1.408746 [51200/60000]\n",
      "loss: 1.240324 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 57.1%, Avg loss: 0.022804 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 1.276374 [    0/60000]\n",
      "loss: 1.524433 [ 6400/60000]\n",
      "loss: 1.596043 [12800/60000]\n",
      "loss: 1.380386 [19200/60000]\n",
      "loss: 1.381055 [25600/60000]\n",
      "loss: 1.498136 [32000/60000]\n",
      "loss: 1.253314 [38400/60000]\n",
      "loss: 1.417307 [44800/60000]\n",
      "loss: 1.320813 [51200/60000]\n",
      "loss: 1.205331 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 57.3%, Avg loss: 0.021922 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 1.299943 [    0/60000]\n",
      "loss: 1.354113 [ 6400/60000]\n",
      "loss: 1.491528 [12800/60000]\n",
      "loss: 1.288916 [19200/60000]\n",
      "loss: 1.273037 [25600/60000]\n",
      "loss: 1.228926 [32000/60000]\n",
      "loss: 1.131825 [38400/60000]\n",
      "loss: 1.529472 [44800/60000]\n",
      "loss: 1.099248 [51200/60000]\n",
      "loss: 1.601252 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 57.8%, Avg loss: 0.021316 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 1.319079 [    0/60000]\n",
      "loss: 1.591193 [ 6400/60000]\n",
      "loss: 1.493165 [12800/60000]\n",
      "loss: 1.135988 [19200/60000]\n",
      "loss: 1.652973 [25600/60000]\n",
      "loss: 1.401969 [32000/60000]\n",
      "loss: 1.310532 [38400/60000]\n",
      "loss: 1.255432 [44800/60000]\n",
      "loss: 1.291118 [51200/60000]\n",
      "loss: 1.094361 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 58.1%, Avg loss: 0.020852 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# Initialize the loss function\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "epochs = 10\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train_loop(train_dataloader, model, loss_fn, optimizer)\n",
    "    test_loop(test_dataloader, model, loss_fn)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved PyTorch Model State to model.pth\n"
     ]
    }
   ],
   "source": [
    "# Saving models\n",
    "torch.save(model.state_dict(), \"data/model.pth\")\n",
    "print(\"Saved PyTorch Model State to model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\johna\\AppData\\Local\\Temp\\ipykernel_30616\\3034000960.py:9: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load('data/model.pth'))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "NeuralNetwork(\n",
       "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "  (linear_relu_stack): Sequential(\n",
       "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
       "    (5): ReLU()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the model\n",
    "import onnxruntime\n",
    "import onnx\n",
    "import torch.onnx as onnx\n",
    "import torchvision.models as models\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "model = NeuralNetwork()\n",
    "model.load_state_dict(torch.load('data/model.pth'))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Inference\n",
    "# exporting the model to ONNX\n",
    "input_image = torch.zeros((1,28,28))\n",
    "onnx_model = 'data/model.onnx'\n",
    "onnx.export(model, input_image, onnx_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")\n",
    "\n",
    "classes = [\n",
    "    \"T-shirt/top\",\n",
    "    \"Trouser\",\n",
    "    \"Pullover\",\n",
    "    \"Dress\",\n",
    "    \"Coat\",\n",
    "    \"Sandal\",\n",
    "    \"Shirt\",\n",
    "    \"Sneaker\",\n",
    "    \"Bag\",\n",
    "    \"Ankle boot\",\n",
    "]\n",
    "x, y = test_data[0][0], test_data[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: \"Sneaker\", Actual: \"Ankle boot\"\n"
     ]
    }
   ],
   "source": [
    "session = onnxruntime.InferenceSession(onnx_model, None)\n",
    "input_name = session.get_inputs()[0].name\n",
    "output_name = session.get_outputs()[0].name\n",
    "\n",
    "result = session.run([output_name], {input_name: x.numpy()})\n",
    "predicted, actual = classes[result[0][0].argmax(0)], classes[y]\n",
    "print(f'Predicted: \"{predicted}\", Actual: \"{actual}\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class: tensor([8])\n"
     ]
    }
   ],
   "source": [
    "# Execute the forward \n",
    "X = torch.rand(1, 28, 28, device=device)\n",
    "logits = model(X)\n",
    "pred_probab = nn.Softmax(dim=1)(logits)\n",
    "y_pred = pred_probab.argmax(1)\n",
    "print(f\"Predicted class: {y_pred}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Linear weights: Parameter containing:\n",
      "tensor([[ 0.0343, -0.0243, -0.0176,  ..., -0.0265,  0.0078, -0.0345],\n",
      "        [ 0.0172, -0.0147,  0.0220,  ..., -0.0148,  0.0159, -0.0016],\n",
      "        [-0.0264, -0.0203,  0.0355,  ...,  0.0087, -0.0325, -0.0116],\n",
      "        ...,\n",
      "        [-0.0024, -0.0227, -0.0156,  ..., -0.0235,  0.0313,  0.0160],\n",
      "        [-0.0260,  0.0131, -0.0018,  ...,  0.0021,  0.0157,  0.0275],\n",
      "        [-0.0230, -0.0304,  0.0150,  ..., -0.0316, -0.0148, -0.0174]],\n",
      "       requires_grad=True) \n",
      "\n",
      "First Linear biases: Parameter containing:\n",
      "tensor([ 0.0339, -0.0069, -0.0153, -0.0154,  0.0213, -0.0254, -0.0132,  0.0130,\n",
      "         0.0039, -0.0213,  0.0146,  0.0060, -0.0066,  0.0268,  0.0342, -0.0108,\n",
      "         0.0312, -0.0108,  0.0285, -0.0054,  0.0280, -0.0030,  0.0068,  0.0043,\n",
      "         0.0006,  0.0440,  0.0028,  0.0031,  0.0104,  0.0013,  0.0210,  0.0161,\n",
      "        -0.0338, -0.0297, -0.0212,  0.0142,  0.0144, -0.0090, -0.0052,  0.0035,\n",
      "        -0.0082, -0.0106,  0.0220, -0.0330, -0.0005, -0.0313, -0.0138, -0.0167,\n",
      "         0.0287, -0.0185,  0.0186,  0.0181, -0.0324,  0.0320,  0.0007,  0.0048,\n",
      "         0.0083,  0.0204, -0.0051, -0.0357, -0.0206, -0.0111,  0.0267, -0.0036,\n",
      "         0.0373,  0.0127, -0.0107,  0.0092,  0.0332, -0.0027, -0.0166, -0.0286,\n",
      "        -0.0152,  0.0050,  0.0093,  0.0295,  0.0129,  0.0212,  0.0256, -0.0295,\n",
      "         0.0258, -0.0005,  0.0315,  0.0196,  0.0148, -0.0173,  0.0251, -0.0077,\n",
      "        -0.0074, -0.0297, -0.0013,  0.0074,  0.0089, -0.0336,  0.0136,  0.0166,\n",
      "         0.0136, -0.0121, -0.0196,  0.0199, -0.0054, -0.0297, -0.0085,  0.0062,\n",
      "        -0.0261,  0.0196, -0.0111,  0.0242, -0.0214,  0.0145,  0.0084, -0.0231,\n",
      "         0.0381,  0.0040,  0.0431,  0.0427, -0.0298,  0.0271,  0.0134, -0.0181,\n",
      "        -0.0079,  0.0280,  0.0065,  0.0314,  0.0143, -0.0129,  0.0187,  0.0309,\n",
      "         0.0104, -0.0233,  0.0058, -0.0339,  0.0339,  0.0229, -0.0298,  0.0365,\n",
      "         0.0335,  0.0371,  0.0264,  0.0167, -0.0131, -0.0157,  0.0194, -0.0297,\n",
      "         0.0238,  0.0110,  0.0207,  0.0360, -0.0012,  0.0165, -0.0289,  0.0081,\n",
      "         0.0320, -0.0182,  0.0144,  0.0272, -0.0090,  0.0258,  0.0291, -0.0088,\n",
      "         0.0083, -0.0187, -0.0268,  0.0062,  0.0055, -0.0200,  0.0014,  0.0332,\n",
      "        -0.0318, -0.0330,  0.0418,  0.0322,  0.0057,  0.0246, -0.0012,  0.0357,\n",
      "         0.0100,  0.0113, -0.0248, -0.0321,  0.0273, -0.0307, -0.0235,  0.0271,\n",
      "        -0.0192,  0.0152,  0.0244, -0.0111,  0.0110,  0.0160,  0.0109, -0.0278,\n",
      "         0.0330,  0.0238,  0.0011,  0.0116,  0.0001, -0.0208,  0.0364,  0.0085,\n",
      "        -0.0054,  0.0056, -0.0296, -0.0038, -0.0093, -0.0123, -0.0282,  0.0085,\n",
      "         0.0287,  0.0306,  0.0095,  0.0086, -0.0017, -0.0127,  0.0217, -0.0155,\n",
      "         0.0148,  0.0145,  0.0149,  0.0351,  0.0386,  0.0074, -0.0208, -0.0138,\n",
      "         0.0142, -0.0247, -0.0101, -0.0158,  0.0022, -0.0303,  0.0054, -0.0159,\n",
      "        -0.0146, -0.0182, -0.0085, -0.0023,  0.0239,  0.0136,  0.0187,  0.0002,\n",
      "        -0.0153, -0.0308,  0.0170,  0.0272,  0.0106,  0.0200,  0.0184, -0.0078,\n",
      "        -0.0103, -0.0104, -0.0117, -0.0176,  0.0121, -0.0097, -0.0070, -0.0234,\n",
      "         0.0206, -0.0206,  0.0130, -0.0311, -0.0049,  0.0341,  0.0290,  0.0089,\n",
      "        -0.0225, -0.0173, -0.0203,  0.0231,  0.0116,  0.0279, -0.0247,  0.0176,\n",
      "        -0.0178,  0.0041,  0.0166, -0.0141, -0.0208,  0.0074, -0.0145, -0.0121,\n",
      "         0.0132,  0.0002, -0.0208,  0.0446,  0.0159, -0.0015, -0.0272,  0.0211,\n",
      "         0.0312, -0.0089, -0.0074,  0.0260, -0.0230, -0.0139, -0.0114,  0.0241,\n",
      "        -0.0303,  0.0370,  0.0028, -0.0087,  0.0138,  0.0139,  0.0176,  0.0247,\n",
      "         0.0245, -0.0219,  0.0017,  0.0046,  0.0468,  0.0096,  0.0332,  0.0330,\n",
      "         0.0126,  0.0226, -0.0090, -0.0125, -0.0037,  0.0349, -0.0161, -0.0094,\n",
      "         0.0307, -0.0273,  0.0086,  0.0135, -0.0039, -0.0145,  0.0064, -0.0185,\n",
      "         0.0045,  0.0174,  0.0354,  0.0068,  0.0242, -0.0191,  0.0316,  0.0343,\n",
      "        -0.0327,  0.0075,  0.0045,  0.0045,  0.0192, -0.0140,  0.0289, -0.0290,\n",
      "        -0.0218, -0.0285,  0.0090,  0.0012, -0.0207,  0.0197, -0.0262, -0.0300,\n",
      "         0.0076,  0.0351,  0.0124,  0.0119,  0.0273,  0.0293,  0.0309,  0.0191,\n",
      "         0.0046, -0.0189, -0.0242, -0.0029,  0.0007, -0.0232, -0.0209,  0.0063,\n",
      "        -0.0089,  0.0237, -0.0201, -0.0278, -0.0343,  0.0243,  0.0375, -0.0025,\n",
      "        -0.0201,  0.0374, -0.0157,  0.0481,  0.0056, -0.0119, -0.0143, -0.0267,\n",
      "        -0.0321, -0.0035, -0.0331,  0.0048, -0.0022, -0.0347,  0.0150,  0.0102,\n",
      "        -0.0023,  0.0266,  0.0376, -0.0294, -0.0204, -0.0232,  0.0126,  0.0390,\n",
      "         0.0244, -0.0002,  0.0055,  0.0351, -0.0039, -0.0275,  0.0144,  0.0387,\n",
      "        -0.0253,  0.0030, -0.0180, -0.0178, -0.0241,  0.0298, -0.0193, -0.0173,\n",
      "         0.0036,  0.0329, -0.0200,  0.0023, -0.0067, -0.0311, -0.0068, -0.0257,\n",
      "         0.0272,  0.0007, -0.0269, -0.0169, -0.0178, -0.0330, -0.0132, -0.0036,\n",
      "         0.0113, -0.0057,  0.0138,  0.0104, -0.0169,  0.0002,  0.0060,  0.0327,\n",
      "         0.0010, -0.0129,  0.0107, -0.0089,  0.0180, -0.0207,  0.0277, -0.0133,\n",
      "        -0.0146, -0.0035,  0.0325,  0.0087,  0.0208, -0.0178,  0.0174, -0.0035,\n",
      "        -0.0040, -0.0322, -0.0026, -0.0151, -0.0249,  0.0285,  0.0208, -0.0094,\n",
      "         0.0356, -0.0380,  0.0148,  0.0085,  0.0379, -0.0088, -0.0208, -0.0233,\n",
      "        -0.0112, -0.0272, -0.0051,  0.0070,  0.0010,  0.0187,  0.0049,  0.0057,\n",
      "        -0.0161,  0.0304,  0.0241,  0.0135,  0.0116, -0.0309, -0.0238,  0.0103,\n",
      "        -0.0116, -0.0072,  0.0191,  0.0174, -0.0148, -0.0126,  0.0019,  0.0313,\n",
      "        -0.0039,  0.0304,  0.0008, -0.0143,  0.0186, -0.0362, -0.0078,  0.0340,\n",
      "         0.0115,  0.0093,  0.0060, -0.0093, -0.0039, -0.0330,  0.0042, -0.0331],\n",
      "       requires_grad=True) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Weight and Bias\n",
    "print(f\"First Linear weights: {model.linear_relu_stack[0].weight} \\n\")\n",
    "print(f\"First Linear biases: {model.linear_relu_stack[0].bias} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 28, 28])\n",
      "tensor([[0.5171, 0.6344, 0.1499,  ..., 0.5992, 0.6725, 0.9575],\n",
      "        [0.2872, 0.1396, 0.1416,  ..., 0.8115, 0.6580, 0.2655],\n",
      "        [0.1061, 0.1373, 0.2609,  ..., 0.4297, 0.0294, 0.1394]])\n"
     ]
    }
   ],
   "source": [
    "# Model layers\n",
    "input_image = torch.rand(3, 28,28)\n",
    "print(input_image.size())\n",
    "\n",
    "# nn.Flatten\n",
    "flatten = nn.Flatten()\n",
    "flat_image = flatten(input_image)\n",
    "print(flat_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 20])\n",
      "Before ReLU: tensor([[-0.4006, -0.2116,  0.5496,  0.7501, -0.0242, -0.3203,  0.2135, -0.1093,\n",
      "          0.0547, -0.3407, -0.3997,  0.6364, -0.1123, -0.3148, -0.0125,  0.1390,\n",
      "         -0.2662, -0.8416,  0.2030, -0.1344],\n",
      "        [-0.2807,  0.3322,  0.4258,  0.4612,  0.2416, -0.5067,  0.1763, -0.0357,\n",
      "          0.3394, -0.1820, -0.3676,  0.5069,  0.0657, -0.7062,  0.0491,  0.0610,\n",
      "          0.1415, -0.9967,  0.0993, -0.0356],\n",
      "        [-0.3394,  0.0897,  0.5178,  0.2155,  0.1957, -0.2479,  0.4746,  0.1045,\n",
      "          0.5691, -0.6181, -0.0823,  0.7801, -0.2778, -0.7639,  0.1005,  0.2597,\n",
      "         -0.2077, -0.9008,  0.3815, -0.0729]], grad_fn=<AddmmBackward0>)\n",
      "\n",
      "\n",
      "After ReLU: tensor([[0.0000, 0.0000, 0.5496, 0.7501, 0.0000, 0.0000, 0.2135, 0.0000, 0.0547,\n",
      "         0.0000, 0.0000, 0.6364, 0.0000, 0.0000, 0.0000, 0.1390, 0.0000, 0.0000,\n",
      "         0.2030, 0.0000],\n",
      "        [0.0000, 0.3322, 0.4258, 0.4612, 0.2416, 0.0000, 0.1763, 0.0000, 0.3394,\n",
      "         0.0000, 0.0000, 0.5069, 0.0657, 0.0000, 0.0491, 0.0610, 0.1415, 0.0000,\n",
      "         0.0993, 0.0000],\n",
      "        [0.0000, 0.0897, 0.5178, 0.2155, 0.1957, 0.0000, 0.4746, 0.1045, 0.5691,\n",
      "         0.0000, 0.0000, 0.7801, 0.0000, 0.0000, 0.1005, 0.2597, 0.0000, 0.0000,\n",
      "         0.3815, 0.0000]], grad_fn=<ReluBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# nn.Linear\n",
    "layer1 = nn.Linear(in_features=28*28, out_features=20)\n",
    "hidden1 = layer1(flat_image)\n",
    "print(hidden1.size())\n",
    "\n",
    "# nn.ReLU\n",
    "print(f\"Before ReLU: {hidden1}\\n\\n\")\n",
    "hidden1 = nn.ReLU()(hidden1)\n",
    "print(f\"After ReLU: {hidden1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nn.Sequential\n",
    "seq_modules = nn.Sequential(\n",
    "    flatten,\n",
    "    layer1,\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(20, 10)\n",
    ")\n",
    "input_image = torch.rand(3,28,28)\n",
    "logits = seq_modules(input_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nn.Softmax\n",
    "softmax = nn.Softmax(dim=1)\n",
    "pred_probab = softmax(logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model structure:  NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
      "    (5): ReLU()\n",
      "  )\n",
      ") \n",
      "\n",
      "\n",
      "Layer: linear_relu_stack.0.weight | Size: torch.Size([512, 784]) | Values : tensor([[ 0.0343, -0.0243, -0.0176,  ..., -0.0265,  0.0078, -0.0345],\n",
      "        [ 0.0172, -0.0147,  0.0220,  ..., -0.0148,  0.0159, -0.0016]],\n",
      "       grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: linear_relu_stack.0.bias | Size: torch.Size([512]) | Values : tensor([ 0.0339, -0.0069], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: linear_relu_stack.2.weight | Size: torch.Size([512, 512]) | Values : tensor([[ 0.0423,  0.0279, -0.0216,  ...,  0.0179,  0.0002, -0.0074],\n",
      "        [-0.0004, -0.0321,  0.0244,  ...,  0.0352,  0.0101, -0.0357]],\n",
      "       grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: linear_relu_stack.2.bias | Size: torch.Size([512]) | Values : tensor([-0.0336, -0.0066], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: linear_relu_stack.4.weight | Size: torch.Size([10, 512]) | Values : tensor([[ 0.0293, -0.0360, -0.0172,  ...,  0.0290,  0.0302, -0.0136],\n",
      "        [-0.0588,  0.0166, -0.0745,  ...,  0.0512, -0.0111, -0.0064]],\n",
      "       grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: linear_relu_stack.4.bias | Size: torch.Size([10]) | Values : tensor([-0.0118,  0.0466], grad_fn=<SliceBackward0>) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Model parameters\n",
    "print(\"Model structure: \", model, \"\\n\\n\")\n",
    "\n",
    "for name, param in model.named_parameters():\n",
    "    print(f\"Layer: {name} | Size: {param.size()} | Values : {param[:2]} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Automatic differentiation with\n",
    "\"\"\"\n",
    "The back and forward process of retraining the model over \n",
    "time to reduce the loss to 0 is called the gradient descent\n",
    "\"\"\"\n",
    "x = torch.ones(5)\n",
    "y = torch.zeros(3)\n",
    "w = torch.randn(5, 3, requires_grad=True)\n",
    "b = torch.randn(3, requires_grad=True)\n",
    "z = torch.matmul(x, w) + b\n",
    "loss = torch.nn.functional.binary_cross_entropy_with_logits(z, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: tensor([1., 1., 1., 1., 1.])\n",
      "y: tensor([0., 0., 0.])\n",
      "w: tensor([[ 0.6947,  1.0184, -1.2398],\n",
      "        [-0.3285, -0.4938,  0.9389],\n",
      "        [ 0.2005,  0.8191, -0.0051],\n",
      "        [ 1.4920,  0.2897, -1.4613],\n",
      "        [-0.0882,  0.6512,  0.2333]], requires_grad=True)\n",
      "b: tensor([-0.4235, -0.2348,  0.5172], requires_grad=True)\n",
      "z: tensor([ 1.5470,  2.0497, -1.0169], grad_fn=<AddBackward0>)\n",
      "loss: tensor(1.4065, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(\"x:\", x)\n",
    "print(\"y:\", y)\n",
    "print(\"w:\", w)\n",
    "print(\"b:\", b)\n",
    "print(\"z:\", z)\n",
    "print(\"loss:\", loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient function of z = <AddBackward0 object at 0x0000023B0EE35270>\n",
      "Gradient function of loss = <BinaryCrossEntropyWithLogitsBackward0 object at 0x0000023B0EE35270>\n",
      "None\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Tensors, functions and computational graphs\n",
    "print('Gradient function of z =', z.grad_fn)\n",
    "print('Gradient function of loss =', loss.grad_fn)\n",
    "\n",
    "# Computing gradients\n",
    "\"\"\"\n",
    "If we need to do several backward calls on the same graph, \n",
    "we need to pass retain_graph=True to the backward call.\n",
    "\"\"\"\n",
    "loss.backward\n",
    "print(w.grad)\n",
    "print(b.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "False\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "# Disabling gradient tracking\n",
    "\"\"\"\n",
    "Cases when we don't need to do that, for example, \n",
    "when we've trained the model and just want to apply \n",
    "it to some input data; only want to \n",
    "do forward computations through the network.\n",
    "\"\"\"\n",
    "z = torch.matmul(x, w) + b\n",
    "print(z.requires_grad)\n",
    "\n",
    "# Approach 1\n",
    "with torch.no_grad():\n",
    "    z = torch.matmul(x , w) + b\n",
    "print(z.requires_grad)\n",
    "\n",
    "# Approach 2 to achieve above results\n",
    "z = z = torch.matmul(x, w) + b\n",
    "z_det = z.detach()\n",
    "print(z_det.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First call\n",
      " tensor([[4., 2., 2., 2., 2.],\n",
      "        [2., 4., 2., 2., 2.],\n",
      "        [2., 2., 4., 2., 2.],\n",
      "        [2., 2., 2., 4., 2.],\n",
      "        [2., 2., 2., 2., 4.]])\n",
      "\n",
      "Second call\n",
      " tensor([[8., 4., 4., 4., 4.],\n",
      "        [4., 8., 4., 4., 4.],\n",
      "        [4., 4., 8., 4., 4.],\n",
      "        [4., 4., 4., 8., 4.],\n",
      "        [4., 4., 4., 4., 8.]])\n",
      "\n",
      "Call after zeroing gradients\n",
      " tensor([[4., 2., 2., 2., 2.],\n",
      "        [2., 4., 2., 2., 2.],\n",
      "        [2., 2., 4., 2., 2.],\n",
      "        [2., 2., 2., 4., 2.],\n",
      "        [2., 2., 2., 2., 4.]])\n"
     ]
    }
   ],
   "source": [
    "# Tensor gradients and Jacobian products\n",
    "inp = torch.eye(5, requires_grad=True)\n",
    "out = (inp+1).pow(2)\n",
    "out.backward(torch.ones_like(inp), retain_graph=True)\n",
    "print(\"First call\\n\", inp.grad)\n",
    "out.backward(torch.ones_like(inp), retain_graph=True)\n",
    "print(\"\\nSecond call\\n\", inp.grad)\n",
    "inp.grad.zero_()\n",
    "out.backward(torch.ones_like(inp), retain_graph=True)\n",
    "print(\"\\nCall after zeroing gradients\\n\", inp.grad)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
